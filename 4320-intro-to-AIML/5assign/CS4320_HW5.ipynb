{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkI0MF7GeFft",
    "tags": []
   },
   "source": [
    "# CS4320 - Introduction to Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ST33IfEfeQD"
   },
   "source": [
    "**Please type your name and A number here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FLXysdGVfflx"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Please enter your link to chatgpt conversation in the above quotation marks, thanks!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/cartwatson/course-work/4320-intro-to-AIML/5assign/CS4320_HW5.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cartwatson/course-work/4320-intro-to-AIML/5assign/CS4320_HW5.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39massert\u001b[39;00m A_number \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPlease enter your A-number in the above quotation marks, thanks!\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cartwatson/course-work/4320-intro-to-AIML/5assign/CS4320_HW5.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m credit \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/cartwatson/course-work/4320-intro-to-AIML/5assign/CS4320_HW5.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39massert\u001b[39;00m credit \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPlease enter your link to chatgpt conversation in the above quotation marks, thanks!\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Please enter your link to chatgpt conversation in the above quotation marks, thanks!"
     ]
    }
   ],
   "source": [
    "Name = \"Carter Watson\"\n",
    "assert Name != \"\", 'Please enter your name in the above quotation marks, thanks!'\n",
    "\n",
    "A_number = \"A02312565\"\n",
    "assert A_number != \"\", 'Please enter your A-number in the above quotation marks, thanks!'\n",
    "\n",
    "credit = \"\"\n",
    "assert credit != \"\", 'Please enter your link to chatgpt conversation in the above quotation marks, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WDio5y1eFfv"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7y-HFFCheFfv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdtRmV4OeFfx"
   },
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwFekNeueFfx"
   },
   "source": [
    "rubric={points:12}\n",
    "\n",
    "Consider the problem of predicting whether a patient has a disease or not. Below are confusion matrices of two machine learning models: Model A and Model B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRoz7AhDeFfx"
   },
   "source": [
    "- Model A confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "SYOzjFReeFfx",
    "outputId": "0c07d02d-786f-4a36-da16-8f1ea801d938",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted disease</th>\n",
       "      <th>Predicted no disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual disease</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual no disease</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted disease  Predicted no disease\n",
       "Actual disease                     3                    10\n",
       "Actual no disease                  1                   106"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_A = pd.DataFrame(\n",
    "    [[3, 10],\n",
    "     [1, 106]],\n",
    "    columns=[\"Predicted disease\", \"Predicted no disease\"],\n",
    "    index=[\"Actual disease\", \"Actual no disease\"])\n",
    "\n",
    "cm_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5tSDg_7eFfx"
   },
   "source": [
    "- Model B confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "5kSGQd6heFfx",
    "outputId": "c55d75e7-aa7c-402c-edbe-90f50efa2cf2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted disease</th>\n",
       "      <th>Predicted no disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual disease</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual no disease</th>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Predicted disease  Predicted no disease\n",
       "Actual disease                     8                     5\n",
       "Actual no disease                 12                    95"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_B = pd.DataFrame(\n",
    "    [[8, 5],\n",
    "     [12, 95]],\n",
    "    columns=[\"Predicted disease\", \"Predicted no disease\"],\n",
    "    index=[\"Actual disease\", \"Actual no disease\"])\n",
    "\n",
    "cm_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_RV8kC9eFfy"
   },
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HOgnV2QeFfy"
   },
   "source": [
    "Type your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygJsSWQfeFfy"
   },
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FVO3UX15eFfy"
   },
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tL_fgUTWeFfy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = None  # Replace your code here\n",
    "results_dict[\"B\"][\"accuracy\"] = None  # Replace your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TxMy9ppeFfz"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABI8QfCmeFfz"
   },
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dYMiWCJeFfz"
   },
   "source": [
    "Type your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZF09utdeFfz"
   },
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without calling `scikit-learn` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPvDMji6eFfz"
   },
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = None  # Replace your code here\n",
    "results_dict[\"B\"][\"precision\"] = None  # Replace your code here\n",
    "results_dict[\"A\"][\"recall\"] = None  # Replace your code here\n",
    "results_dict[\"B\"][\"recall\"] = None  # Replace your code here\n",
    "results_dict[\"A\"][\"f1\"] = None  # Replace your code here\n",
    "results_dict[\"B\"][\"f1\"] = None  # Replace your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEv7GVJreFf0"
   },
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ax9DxZdUeFf0"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYkWHAoneFf0"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yme2MC0peFf1"
   },
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDs2ov0NeFf1"
   },
   "source": [
    "Type your answer here:\n",
    "\n",
    "1.\n",
    "\n",
    "2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yihl_ZBIeFf1"
   },
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "rubric={points:48}\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IQcvXYSeFf1"
   },
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRvv0nfFeFf1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFgv2WqzeFf2"
   },
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split.(Print out the count of each class) Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItgMqI06pfps"
   },
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckqQlCUPpr5y"
   },
   "source": [
    "Type your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vg6TJikkeFf2"
   },
   "source": [
    "### 2.2 Column transformer \n",
    "rubric={points:12}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "You can create a column transformer in two ways:\n",
    "- by using [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n",
    "- by using [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) \n",
    "\n",
    "\n",
    "In each case, briefly explain your rationale with 1-2 sentences. You do not need an explanation for every feature, but for every group of features that are being transformed the same way. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KThomwT7eFf2"
   },
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6onearfVqHNm"
   },
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQR4flcoqQrZ"
   },
   "source": [
    "Briefly explain your rationale:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwXyKtMoeFf2"
   },
   "source": [
    "### 2.3 Visualizing the transformed data \n",
    "rubric={points:1}\n",
    "\n",
    "Fit and transform your `ColumnTransformer` on your training set. Print the first 5 rows of the transformed data as a dataframe (not numpy array). See lecture for code that can get you the new column names after transforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcjwli6hqkf7"
   },
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j8EOmyDeFf3"
   },
   "source": [
    "### 2.4 Area code feature\n",
    "rubric={points:1}\n",
    "\n",
    "The original dataset had a feature called `area code`. Let's assume we encoded this feature with one-hot encoding.\n",
    "\n",
    "1. The area codes were numbers to begin with. Why do we want to use one-hot encoding on this feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22UEuAxpeFf3"
   },
   "source": [
    "Type your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHiMEJxreFf3"
   },
   "source": [
    "### 2.5 Dummy classifier\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Create a `DummyClassifier`. Report the following scoring metrics via cross-validation: accuracy, precision, recall, f1-score. Briefly comment on your results, including any *warnings* the code produces (2 sentences max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQrb8Zh9sPbl"
   },
   "outputs": [],
   "source": [
    "# Insert your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nAgRCzAeFf3"
   },
   "source": [
    "### 2.6 Logistic regression\n",
    "rubric={points:4} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a `LogisticRegression`. \n",
    "2. Report the same metrics as in the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHYizbqlsp4L"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCVIx26ceFf3"
   },
   "source": [
    "### 2.7 Logistic regression with `class_weight`\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toV8bNhWte_L"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h26N4Jf6eFf4"
   },
   "source": [
    "### 2.8 Hyperparameter optimization\n",
    "rubric={points:6}\n",
    "\n",
    "Now let's tune the hyperparameters of our `LogisticRegression` using `GridSearchCV` to maximize cross-validation f1 score. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Jointly optimize `C` (choose some reasonable values) and `class_weight` (`None` vs. `'balanced'`) with `GridSearchCV` and `scoring=\"f1\"`. \n",
    "2. What values of `C` and `class_weight` are chosen ? (Print out best \"C\" and best \"class_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNEGqT62tzVr"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gVDoVqYeFf4"
   },
   "source": [
    "### 2.9 Test results\n",
    "rubric={points:16}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Confusion matrix. \n",
    "    - Classification report. \n",
    "    - Precision-recall curve with average precision score.     \n",
    "    - ROC curve with AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXQu7nmON-zn"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF0zb2tZeFf4"
   },
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7R56w3feFf4"
   },
   "source": [
    "rubric={points=40}\n",
    "\n",
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tc76KkZQeFf4"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34Idh3KqeFf5"
   },
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (80%) and test (20%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` in train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXI0U9i2xNZ6"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Qtt7GOHeFf5"
   },
   "source": [
    "### 3.2 Baseline: DummyRegressor \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `DummyRegressor` with default scoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEHMQtFQxxty"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNP4iZ1seFf5"
   },
   "source": [
    "### 3.3 Different regressors\n",
    "rubric={points:8}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for different regressors (`models`) and different scoring metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrwqh6W7eFf5"
   },
   "outputs": [],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sa69K_O1yQ-D"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kILRK1etybC7"
   },
   "source": [
    "Type your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgRJM2qAeFf5"
   },
   "source": [
    "### 3.4 Hyperparameter optimization \n",
    "rubric={points:8}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose the metric of your choice for hyperparameter optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxKWDZvJeFf5"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8YA-3qMzfJS"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H2AzBR8eFf6"
   },
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try the best model on the test set and use mape metric to evaluate your results.\n",
    "2. Briefly comment on the results. (1 to 2 sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-a5CfkjzssR"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdx4hxrs23Fl"
   },
   "source": [
    "Type your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pGRO01CeFf6"
   },
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:6}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Visualize coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: features and coefficients. Use the `Ridge` model with best hyperparameters. Sort the coefficients in descending order. \n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ajfsNmo0B6p"
   },
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YaEJXrY26WR"
   },
   "source": [
    "Type your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQNJld4PeFf6"
   },
   "source": [
    "## Submission instructions\n",
    "<hr>\n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
    "2. Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Please keep your notebook clean and delete any throwaway code."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
